
@inproceedings{Alo05,
  title = {On {{Solving Optimization Problems Using Boolean Satisfiability}}},
  booktitle = {Proceeding of the {{First International Conference}} on {{Modeling}}, {{Simulation}} and {{Applied Optimization}}},
  author = {Aloul, Fadi A.},
  year = {2005},
  month = feb,
  address = {{Sharjah, U.A.E.}},
  doi = {10.1.1.149.145},
  abstract = {The last few years have seen significant advances in Boolean satisfiability (SAT) solving. This has lead to the successful deployment of SAT solvers in a wide range of problems in Engineering and Computer Science. In general, most SAT solvers are applied to Boolean decision problems that are expressed in conjunctive normal form (CNF). While this input format is applicable to some engineering tasks, it poses a significant obstacle to others. One of the main advances in SAT is generalizing SAT solvers to handle stronger representation of constraints. Specifically, pseudo-Boolean (PB) constraints which are efficient in representing counting constraints and can replace an exponential number of CNF constraints. Another significant advantage of PB constraints is its ability to express Boolean optimization problems. This allows for new applications that were never handled by SAT solvers before. In this paper, we describe two methods to solve Boolean optimization problems using SAT solvers. Both methods are implemented and evaluated using the SAT solver PBS. We develop an adaptive flow that analyzes a given Boolean optimization problem and selects the solving method that best fits the problem characteristics. Empirical evidence on a variety of benchmarks shows that both methods are competitive. The results also show that SAT-based methods tend to outperform generic integer linear programming (ILP) solvers.},
  file = {C\:\\Users\\disc\\Zotero\\storage\\KDHEEVST\\Aloul - On Solving Optimization Problems Using Boolean Sat.pdf;C\:\\Users\\disc\\Zotero\\storage\\DPQ7C7T5\\download.html}
}

@article{Amb05,
  title = {Quantum Search Algorithms},
  author = {Ambainis, Andris},
  year = {2005},
  month = apr,
  journal = {arXiv:quant-ph/0504012},
  eprint = {quant-ph/0504012},
  eprinttype = {arxiv},
  abstract = {We review some of quantum algorithms for search problems: Grover's search algorithm, its generalization to amplitude amplification, the applications of amplitude amplification to various problems and the recent quantum algorithms based on quantum walks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity,Computer Science - Data Structures and Algorithms,Quantum Physics},
  file = {C\:\\Users\\disc\\Zotero\\storage\\VYDTUUFF\\Ambainis - 2005 - Quantum search algorithms.pdf;C\:\\Users\\disc\\Zotero\\storage\\T9GK3SD2\\0504012.html}
}

@incollection{AS96,
  title = {Normal {{Order}} and {{Applicative Order}}},
  booktitle = {Structure and {{Interpretation}} of {{Computer Programs}}},
  author = {Abelson, Harold and Sussman, Gerald Jay},
  year = {1996},
  month = jul,
  pages = {Sec 4.2.1, p.542-544},
  publisher = {{The MIT Press}},
  abstract = {Structure and Interpretation of Computer Programs has had a dramatic impact on computer science curricula over the past decade. This long-awaited revision contains changes throughout the text. There are new implementations of most of the major programming systems in the book, including the interpreters and compilers, and the authors have incorporated many small changes that reflect their experience teaching the course at MIT since the first edition was published. A new theme has been introduced that emphasizes the central role played by different approaches to dealing with time in computational models: objects with state, concurrent programming, functional programming and lazy evaluation, and nondeterministic programming. There are new example sections on higher-order procedures in graphics and on applications of stream processing in numerical programming, and many new exercises. In addition, all the programs have been reworked to run in any Scheme implementation that adheres to the IEEE standard.},
  isbn = {978-0-262-51087-5 978-0-262-31091-8},
  langid = {english},
  keywords = {bic Book Industry Communication::U Computing \& information technology::UY Computer science},
  annotation = {Accepted: 2019-01-17 23:55},
  file = {C\:\\Users\\disc\\Zotero\\storage\\3XQBY8W5\\Abelson and Sussman - 1996 - Structure and Interpretation of Computer Programs.pdf}
}

@inproceedings{BCCZ99,
  title = {Symbolic {{Model Checking}} without {{BDDs}}},
  booktitle = {Tools and {{Algorithms}} for the {{Construction}} and {{Analysis}} of {{Systems}}},
  author = {Biere, Armin and Cimatti, Alessandro and Clarke, Edmund and Zhu, Yunshan},
  editor = {Cleaveland, W. Rance},
  year = {1999},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {193--207},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-49059-0_14},
  abstract = {Symbolic Model Checking [3], [14] has proven to be a powerful technique for the verification of reactive systems. BDDs [2] have traditionally been used as a symbolic representation of the system. In this paper we show how boolean decision procedures, like St\aa lmarck's Method [16] or the Davis \& Putnam Procedure [7], can replace BDDs. This new technique avoids the space blow up of BDDs, generates counterexamples much faster, and sometimes speeds up the verification. In addition, it produces counterexamples of minimal length. We introduce a bounded model checking procedure for LTL which reduces model checking to propositional satisfiability.We show that bounded LTL model checking can be done without a tableau construction. We have implemented a model checker BMC, based on bounded model checking, and preliminary results are presented.},
  isbn = {978-3-540-49059-3},
  langid = {english},
  keywords = {Kripke Structure,Liveness Property,Model Check,Propositional Formula,Symbolic Model Check},
  file = {C\:\\Users\\disc\\Zotero\\storage\\XVRNEGGE\\Biere et al. - 1999 - Symbolic Model Checking without BDDs.pdf}
}

@article{BCM+20,
  title = {Solving {{SAT}} (and {{MaxSAT}}) with a Quantum Annealer: {{Foundations}}, Encodings, and Preliminary Results},
  shorttitle = {Solving {{SAT}} (and {{MaxSAT}}) with a Quantum Annealer},
  author = {Bian, Zhengbing and Chudak, Fabian and Macready, William and Roy, Aidan and Sebastiani, Roberto and Varotti, Stefano},
  year = {2020},
  month = dec,
  journal = {Information and Computation},
  volume = {275},
  pages = {104609},
  issn = {0890-5401},
  doi = {10.1016/j.ic.2020.104609},
  abstract = {Quantum annealers (QAs) are specialized quantum computers that minimize objective functions over discrete variables by physically exploiting quantum effects. Current QA platforms allow for the optimization of quadratic objectives defined over binary variables (qubits), also known as Ising problems. In the last decade, QA systems as implemented by D-Wave have scaled with Moore-like growth. Current architectures provide 2048 sparsely-connected qubits, and continued exponential growth is anticipated, together with increased connectivity. We explore the feasibility of such architectures for solving SAT and MaxSAT problems as QA systems scale. We develop techniques for effectively encoding SAT \textendash and, with some limitations, MaxSAT\textendash{} into Ising problems compatible with sparse QA architectures. We provide the theoretical foundations for this mapping, and present encoding techniques that combine offline Satisfiability and Optimization Modulo Theories with on-the-fly placement and routing. Preliminary empirical tests on a current generation 2048-qubit D-Wave system support the feasibility of the approach for certain SAT and MaxSAT problems.},
  langid = {english},
  keywords = {Chimera graph,Ising model,MaxSAT,Optimization modulo theories,Quadratic unconstrained binary optimization (QUBO),Quantum annealing (QA),SAT,Satisfiability modulo theories},
  file = {C\:\\Users\\disc\\Zotero\\storage\\JKXKV7HC\\Bian et al. - 2020 - Solving SAT (and MaxSAT) with a quantum annealer .pdf;C\:\\Users\\disc\\Zotero\\storage\\V2FGHIEN\\S0890540120300973.html}
}

@inproceedings{BFMP11,
  title = {Why3: {{Shepherd Your Herd}} of {{Provers}}},
  shorttitle = {Why3},
  booktitle = {Boogie 2011: {{First International Workshop}} on {{Intermediate Verification Languages}}},
  author = {Bobot, Fran{\c c}ois and Filli{\^a}tre, Jean-Christophe and March{\'e}, Claude and Paskevich, Andrei},
  year = {2011},
  pages = {53},
  doi = {10/document},
  abstract = {Why3 is the next generation of the Why software verification platform. Why3 clearly separates the purely logical specification part from generation of verification conditions for programs. This article focuses on the former part. Why3 comes with a new enhanced language of logical specification. It features a rich library of proof task transformations that can be chained to produce a suitable input for a large set of theorem provers, including SMT solvers, TPTP provers, as well as interactive proof assistants.},
  langid = {english},
  file = {C\:\\Users\\disc\\Zotero\\storage\\CNYRUYWY\\Bobot et al. - 2011 - Why3 Shepherd Your Herd of Provers.pdf;C\:\\Users\\disc\\Zotero\\storage\\W36BM74C\\hal-00790310.html}
}

@inproceedings{BGV99,
  title = {Microprocessor {{Verification Using Efficient Decision Procedures}} for a {{Logic}} of {{Equality}} with {{Uninterpreted Functions}}},
  booktitle = {Automated {{Reasoning}} with {{Analytic Tableaux}} and {{Related Methods}}},
  author = {Bryant, Randal E. and German, Steven and Velev, Miroslav N.},
  editor = {Murray, Neil V.},
  year = {1999},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1--13},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-48754-9_1},
  abstract = {Modern processors have relatively simple specifications based on their instruction set architectures. Their implementations, however, are very complex, especially with the advent of performance-enhancing techniques such as pipelining, superscalar operation, and speculative execution. Formal techniques to verify that a processor implements its instruction set specification could yield more reliable results at a lower cost than the current simulation-based verification techniques used in industry.The logic of equality with uninterpreted functions (EUF) provides a means of abstracting the manipulation of data by a processor when verifying the correctness of its control logic. Using a method devised by Burch and Dill [BD94], the correctness of a processor can be inferred by deciding the validity of a formula in EUF describing the comparative effect of running one clock cycle of processor operation to that of executing a small number (based on the processor issue rate) of machine instructions.This paper describes recent advances in reducing formulas in EUF to propositional logic. We can then use either Binary Decision Diagrams (BDDs) or satisfiability procedures to determine whether this propositional formula is a tautology. We can exploit characteristics of the formulas generated when modeling processors to significantly reduce the number of propositional variables, and consequently the complexity, of the verification task.},
  isbn = {978-3-540-48754-8},
  langid = {english},
  keywords = {Data Symbol,Decision Procedure,Domain Variable,Function Symbol,Propositional Logic},
  file = {C\:\\Users\\disc\\Zotero\\storage\\HXXCXFT3\\Bryant et al. - 1999 - Microprocessor Verification Using Efficient Decisi.pdf}
}

@article{CGW00,
  title = {Nested {{Quantum Search}} and {{NP-Hard Problems}}},
  author = {Cerf, Nicolas J. and Grover, Lov K. and Williams, Colin P.},
  year = {2000},
  month = may,
  journal = {Applicable Algebra in Engineering, Communication and Computing},
  volume = {10},
  number = {4-5},
  pages = {311--338},
  issn = {0938-1279, 1432-0622},
  doi = {10.1007/s002000050134},
  abstract = {A quantum algorithm is known t{$\surd$}hat solves an unstructured search problem in a number of iterations of order d, where d is the dimension of the search space, whereas any classical algorithm necessarily scales as O(d). It is shown here that an improved quantum search algorithm can be devised that exploits the structure of a tree search problem by nesting this standard search algorithm. The number of iterations required to find the s{$\surd$}olution of an average instance of a constraint satisfaction problem scales as d{$\alpha$}, with a constant {$\alpha$} {$<$} 1 depending on the nesting depth and the problem considered. When applying a single nesting level to a problem with constraints of size 2 such as the graph coloring problem, this constant {$\alpha$} is estimated to be around 0.62 for average instances of maximum difficulty. This corresponds to a square-root speedup over a classical nested search algorithm, of which our presented algorithm is the quantum counterpart.},
  langid = {english},
  file = {C\:\\Users\\disc\\Zotero\\storage\\YGKLGSHF\\Cerf et al. - 2000 - Nested Quantum Search and NP-Hard Problems.pdf}
}

@inproceedings{Coo71,
  title = {The Complexity of Theorem-Proving Procedures},
  booktitle = {Proceedings of the Third Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Cook, Stephen A.},
  year = {1971},
  month = may,
  series = {{{STOC}} '71},
  pages = {151--158},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/800157.805047},
  abstract = {It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be ``reduced'' to the problem of determining whether a given propositional formula is a tautology. Here ``reduced'' means, roughly speaking, that the first problem can be solved deterministically in polynomial time provided an oracle is available for solving the second. From this notion of reducible, polynomial degrees of difficulty are defined, and it is shown that the problem of determining tautologyhood has the same polynomial degree as the problem of determining whether the first of two given graphs is isomorphic to a subgraph of the second. Other examples are discussed. A method of measuring the complexity of proof procedures for the predicate calculus is introduced and discussed.},
  isbn = {978-1-4503-7464-4},
  file = {C\:\\Users\\disc\\Zotero\\storage\\X8TF5CA2\\Cook - 1971 - The complexity of theorem-proving procedures.pdf}
}

@article{dKM21,
  title = {Tensor {{Network Rewriting Strategies}} for {{Satisfiability}} and {{Counting}}},
  author = {{de Beaudrap}, Niel and Kissinger, Aleks and Meichanetzidis, Konstantinos},
  year = {2021},
  month = sep,
  journal = {Electronic Proceedings in Theoretical Computer Science},
  volume = {340},
  eprint = {2004.06455},
  eprinttype = {arxiv},
  pages = {46--59},
  issn = {2075-2180},
  doi = {10.4204/EPTCS.340.3},
  abstract = {We provide a graphical treatment of SAT and \#SAT on equal footing. Instances of \#SAT can be represented as tensor networks in a standard way. These tensor networks are interpreted by diagrams of the ZH-calculus: a system to reason about tensors over C in terms of diagrams built from simple generators, in which computation may be carried out by transformations of diagrams alone. In general, nodes of ZH diagrams take parameters over C which determine the tensor coefficients; for the standard representation of \#SAT instances, the coefficients take the value 0 or 1. Then, by choosing the coefficients of a diagram to range over B, we represent the corresponding instance of SAT. Thus, by interpreting a diagram either over the boolean semiring or the complex numbers, we instantiate either the decision or counting version of the problem. We find that for classes known to be in P, such as 2SAT and \#XORSAT, the existence of appropriate rewrite rules allows for efficient simplification of the diagram, producing the solution in polynomial time. In contrast, for classes known to be NP-complete, such as 3SAT, or \#P-complete, such as \#2SAT, the corresponding rewrite rules introduce hyperedges to the diagrams, in numbers which are not easily bounded above by a polynomial. This diagrammatic approach unifies the diagnosis of the complexity of CSPs and \#CSPs and shows promise in aiding tensor network contraction-based algorithms.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Complexity,Quantum Physics},
  file = {C\:\\Users\\disc\\Zotero\\storage\\CUMJ2K8U\\de Beaudrap et al. - 2021 - Tensor Network Rewriting Strategies for Satisfiabi.pdf;C\:\\Users\\disc\\Zotero\\storage\\PKU4RKXX\\2004.html}
}

@article{DLL62,
  title = {A Machine Program for Theorem-Proving},
  author = {Davis, Martin and Logemann, George and Loveland, Donald},
  year = {1962},
  month = jul,
  journal = {Communications of the ACM},
  volume = {5},
  number = {7},
  pages = {394--397},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/368273.368557},
  abstract = {The programming of a proof procedure is discussed in connection with trial runs and possible improvements.},
  langid = {english},
  file = {C\:\\Users\\disc\\Zotero\\storage\\ZIQVEVCX\\Davis et al. - 1962 - A machine program for theorem-proving.pdf}
}

@inproceedings{Gro96,
  title = {A {{Fast Quantum Mechanical Algorithm}} for {{Database Search}}},
  booktitle = {Proceedings of the {{Twenty-eighth Annual ACM Symposium}} on {{Theory}} of {{Computing}}},
  author = {Grover, Lov K.},
  year = {1996},
  month = may,
  series = {{{STOC}} '96},
  pages = {212--219},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/237814.237866},
  abstract = {Imagine a phone directory containing N names arranged in completely random order. In order to find someone's phone number with a 50\% probability, any classical algorithm (whether deterministic or probabilistic) will need to look at a minimum of N/2 names. Quantum mechanical systems can be in a superposition of states and simultaneously examine multiple names. By properly adjusting the phases of various operations, successful computations reinforce each other while others interfere randomly. As a result, the desired phone number can be obtained in only O(sqrt(N)) steps. The algorithm is within a small constant factor of the fastest possible quantum mechanical algorithm.},
  isbn = {978-0-89791-785-8},
  file = {C\:\\Users\\disc\\Zotero\\storage\\KTLED9PZ\\Grover - 1996 - A Fast Quantum Mechanical Algorithm for Database S.pdf}
}

@article{GZ17,
  title = {A Survey of {{SAT}} Solver},
  author = {Gong, Weiwei and Zhou, Xu},
  year = {2017},
  month = jun,
  journal = {AIP Conference Proceedings},
  volume = {1836},
  number = {1},
  pages = {020059},
  publisher = {{American Institute of Physics}},
  issn = {0094-243X},
  doi = {10.1063/1.4981999},
  file = {C\:\\Users\\disc\\Zotero\\storage\\VVTXKNZJ\\Gong and Zhou - 2017 - A survey of SAT solver.pdf}
}

@misc{Hin18,
  title = {Genomics {{Code Exceeds Exaops}} on {{Summit Supercomputer}}},
  author = {Hines, Jonathan},
  year = {2018},
  month = jun,
  journal = {Oak Ridge Leadership Computing Facility},
  abstract = {ORNL researchers leverage GPU Tensor Cores to deliver unprecedented performance},
  langid = {american},
  file = {C\:\\Users\\disc\\Zotero\\storage\\3NEY8MXD\\genomics-code-exceeds-exaops-on-summit-supercomputer.html}
}

@inproceedings{HMN+11,
  title = {A Short Overview on Modern Parallel {{SAT-solvers}}},
  booktitle = {2011 {{International Conference}} on {{Advanced Computer Science}} and {{Information Systems}}},
  author = {H{\"o}lldobler, Steffen and Manthey, Norbert and Nguyen, Van Hau and Stecklina, Julian and Steinke, Peter},
  year = {2011},
  month = dec,
  pages = {201--206},
  abstract = {This paper surveys modern parallel SAT-solvers. It focusses on recent successful techniques and points out weaknesses that have to be overcome to exploit the full power of modern multi-core processors.},
  keywords = {Computer architecture,Delay,Hardware,Parallel processing,Portfolios,Runtime,Scattering},
  file = {C\:\\Users\\disc\\Zotero\\storage\\W8XZWCXU\\Hölldobler et al. - 2011 - A short overview on modern parallel SAT-solvers.pdf}
}

@techreport{Jor21,
  title = {Quantum {{Algorithm Zoo}}},
  author = {Jordan, Stephen},
  year = {2021},
  month = feb
}

@inproceedings{KSE15,
  title = {On the Parallelization of {{SAT}} Solvers},
  booktitle = {2015 {{Tenth International Conference}} on {{Computer Engineering Systems}} ({{ICCES}})},
  author = {Khalek, Y. A. El and Safar, M. and {El-Kharashi}, M. W.},
  year = {2015},
  month = dec,
  pages = {119--128},
  doi = {10.1109/ICCES.2015.7393031},
  abstract = {This paper presents the main challenges, the hot topics, and the intriguing issues in the area of parallel SAT solving which provides possible directions for future research. It gives a detailed summary for the main features and technologies used in the most widely known and successful parallel SAT solvers and shows the strong points and the shortcomings in them. In addition, it compares between the basic characteristics for these solvers including algorithms, architecture paradigm, scalability, network communication, managing the workload distribution and more. Finally, a new approach is proposed that is expected to be a very promising direction as it copes with the nature of parallel paradigm and results in almost a linear speedup in solving SAT instances, independent of the number of variables of the SAT formula.},
  keywords = {Algorithm design and analysis,architecture paradigm,Boolean Satisfiability SAT,computability,Computer architecture,Computers,Master-slave,network communication,parallel processing,Parallel processing,Parallelism,Partitioning algorithms,Program processors,SAT solver parallelization,satisfiability,scalability,workload distribution},
  file = {C\:\\Users\\disc\\Zotero\\storage\\LEZRGKKB\\Khalek et al. - 2015 - On the parallelization of SAT solvers.pdf}
}

@inproceedings{LAK+14,
  title = {Symbolic Optimization with {{SMT}} Solvers},
  booktitle = {Proceedings of the 41st {{ACM SIGPLAN-SIGACT Symposium}} on {{Principles}} of {{Programming Languages}}},
  author = {Li, Yi and Albarghouthi, Aws and Kincaid, Zachary and Gurfinkel, Arie and Chechik, Marsha},
  year = {2014},
  month = jan,
  pages = {607--618},
  publisher = {{ACM}},
  address = {{San Diego California USA}},
  doi = {10.1145/2535838.2535857},
  abstract = {The rise in efficiency of Satisfiability Modulo Theories (SMT) solvers has created numerous uses for them in software verification, program synthesis, functional programming, refinement types, etc. In all of these applications, SMT solvers are used for generating satisfying assignments (e.g., a witness for a bug) or proving unsatisfiability/validity (e.g., proving that a subtyping relation holds). We are often interested in finding not just an arbitrary satisfying assignment, but one that optimizes (minimizes/maximizes) certain criteria. For example, we might be interested in detecting program executions that maximize energy usage (performance bugs), or synthesizing short programs that do not make expensive API calls. Unfortunately, none of the available SMT solvers offer such optimization capabilities.},
  isbn = {978-1-4503-2544-8},
  langid = {english},
  file = {C\:\\Users\\disc\\Zotero\\storage\\WW2BGYKL\\Li et al. - 2014 - Symbolic optimization with SMT solvers.pdf}
}

@article{NSR02,
  title = {A New {{FPGA}} Detailed Routing Approach via Search-Based {{Boolean}} Satisfiability},
  author = {Nam, Gi-Joon and Sakallah, K.A. and Rutenbar, R.A.},
  year = {2002},
  month = jun,
  journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume = {21},
  number = {6},
  pages = {674--684},
  issn = {1937-4151},
  doi = {10.1109/TCAD.2002.1004311},
  abstract = {Boolean-based routing methods transform the geometric FPGA routing task into a large but atomic Boolean function with the property that any assignment of input variables that satisfies the function specifies a valid routing solution. We present a new search-based satisfiability (SAT) FPGA detailed routing formulation that handles all channels in an FPGA simultaneously. The formulation has the virtue that it considers all nets concurrently allowing higher degrees of freedom for each net, in contrast to the classical one-net-at-a-time approaches and is able to prove the unroutability of a given circuit by demonstrating the absence of a satisfying assignment to the routing Boolean function. To demonstrate the effectiveness of this method, we first present comparative experimental results between integer linear programming (ILP)-based routing, which is an alternative concurrent method, and SAT-based routing. We also present the. first comparisons of search-based Boolean SAT routing results to other conventional routers and offer the first evidence that SAT methods can actually demonstrate the unroutability of a layout. Preliminary experimental results suggest that our approach compares very favorably with both the ILP-based approach and conventional FPGA routers.},
  keywords = {Adaptive arrays,Application specific integrated circuits,Boolean functions,Data structures,Field programmable gate arrays,Input variables,Integer linear programming,Logic design,Programmable logic arrays,Routing},
  file = {C\:\\Users\\disc\\Zotero\\storage\\GG62USC9\\Nam et al. - 2002 - A new FPGA detailed routing approach via search-ba.pdf;C\:\\Users\\disc\\Zotero\\storage\\JIZ8NSJZ\\1004311.html}
}

@inproceedings{OU09,
  title = {C-Sat: {{A Parallel SAT Solver}} for {{Clusters}}},
  shorttitle = {C-Sat},
  booktitle = {Theory and {{Applications}} of {{Satisfiability Testing}} - {{SAT}} 2009},
  author = {Ohmura, Kei and Ueda, Kazunori},
  editor = {Kullmann, Oliver},
  year = {2009},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {524--537},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-02777-2_47},
  abstract = {Parallelizing modern SAT solvers for clusters such as Beowulf is an important challenge both in terms of performance scalability and stability. This paper describes a SAT Solver c-sat, a parallelization of MiniSat using MPI. It employs a layered master-worker architecture, where the masters handle lemma exchange, deletion of redundant lemmas and the dynamic partitioning of search trees, while the workers do search using different decision heuristics and random number seeds. With careful tuning, c-sat showed good speedup over MiniSat with reasonably small communication overhead on various clusters. On an eight-node cluster with two Dual-Core Opterons on each node (32 PEs), c-sat ran at least 23 times faster than MiniSat using 31 PEs (geometric mean; at least 31 times for satisfiable problems) for 189 large-scale problems from SAT Competition and two SAT-Races.},
  isbn = {978-3-642-02777-2},
  langid = {english},
  keywords = {Communication Overhead,Decision Heuristic,Execution Time,Total Execution Time,Total Runtime}
}

@inproceedings{PK00,
  title = {Equivalence Checking Combining a Structural {{SAT-solver}}, {{BDDs}}, and Simulation},
  booktitle = {Proceedings 2000 {{International Conference}} on {{Computer Design}}},
  author = {Paruthi, V. and Kuehlmann, A.},
  year = {2000},
  month = sep,
  pages = {459--464},
  issn = {1063-6404},
  doi = {10.1109/ICCD.2000.878323},
  abstract = {This paper presents a verification technique for functional comparison of large combinational circuits using a novel combination of known approaches. The idea is based on a tight integration of a structural satisfiability (SAT) solver, BDD sweeping, and random simulation; all three working on a shared graph representation of the circuit. The BDD sweeping and SAT solver are applied in an inter-twined manner both controlled by resource limits that are successively increased during each iteration. In this cooperative setting the BDD sweeping incrementally reduces the search space for the SAT solver until the problem is solved or the resource limits are exhausted. This approach improves on previous work in several ways: The integral application of the SAT solver significantly enhances the capacity and efficiency of BDD sweeping and extends its suitability for miscomparing designs. Further, the random simulation algorithm works on the compressed circuit graph and thus runs more efficiently. Our experiments demonstrate that the outlined approach is effective for a large class of equivalence checking instances by automatically adapting to the difficulty of the problem.},
  keywords = {Binary decision diagrams,Boolean functions,Circuit simulation,Combinational circuits,Computational complexity,Data structures,Design methodology,Encoding,Partitioning algorithms,Synthetic aperture sonar},
  file = {C\:\\Users\\disc\\Zotero\\storage\\A2SJCPX4\\Paruthi and Kuehlmann - 2000 - Equivalence checking combining a structural SAT-so.pdf;C\:\\Users\\disc\\Zotero\\storage\\VARHWA5F\\878323.html}
}

@article{SBS96,
  title = {Combinational Test Generation Using Satisfiability},
  author = {Stephan, P. and Brayton, R.K. and {Sangiovanni-Vincentelli}, A.L.},
  year = {1996},
  month = sep,
  journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume = {15},
  number = {9},
  pages = {1167--1176},
  issn = {1937-4151},
  doi = {10.1109/43.536723},
  abstract = {We present a robust, efficient algorithm for combinational test generation using a reduction to satisfiability (SAT). The algorithm, Test Generation Using Satisfiability (TEGUS), solves a simplified test set characteristic equation using straightforward but powerful greedy heuristics, ordering the variables using depth-first search and selecting a variable from the next unsatisfied clause at each branching point. For difficult faults, the computation of global implications is iterated, which finds more implications than previous approaches and subsumes structural heuristics such as unique sensitization. Without random tests or fault simulation, TEGUS completes on every fault in the ISCAS networks, demonstrating its robustness, and is ten times faster for those networks which have been completed by previous algorithms. Our implementation of TEGUS can be used as a base line for comparing test generation algorithms; we present comparisons with 45 recently published algorithms. TEGUS combines the advantages of the elegant organization of SAT-based algorithms with the efficiency of structural algorithms.},
  keywords = {Algorithm design and analysis,Character generation,Circuit faults,Computational modeling,Equations,Logic programming,Logic testing,Polynomials,Power generation,Robustness},
  file = {C\:\\Users\\disc\\Zotero\\storage\\8Q8PBJP2\\Stephan et al. - 1996 - Combinational test generation using satisfiability.pdf;C\:\\Users\\disc\\Zotero\\storage\\R8R3TJB4\\536723.html}
}

@patent{Sta94,
  title = {System for Determining Propositional Logic Theorems by Applying Values and Rules to Triplets That Are Generated from Boolean Formula},
  author = {Stalmarck, Gunnar M. N.},
  year = {1994},
  month = jan,
  number = {US5276897A},
  abstract = {The invention relates to a method and apparatus for theorem checking with the intention in so-called tautology checks of establishing whether or not all possible attributions of the truth values (0 and 1) to variables in a boolean formula render the formula true. The problem of known techniques is that checking of the truth content is effected against all variables in an original formula, which requires many calculations to be made and which is highly time-consuming.     According to the invention, an original formula is divided into part-expressions, so-called triplets, each corresponding to a sub-formula of the original formula, whereafter logic 0's and 1's are instantiated (allotted) to variables in the triplets for the purpose of checking the truth content. The check is thus made against triplets instead of against all variables in the original formula, therewith greatly reducing the number of calculations necessary and providing a considerable saving in time. Apparatus, called a theorem checker, for carrying out the method includes a sequence unit for controlling the calculation sequence, a generator G for generating sequences of ordered variables, a permanent unit P for storing triplets, a plurality of arithmetical units, evaluators (E) and an analyzer A operative to analyze the result obtain from all calculations.},
  assignee = {Stalmarck Gunnar M N},
  nationality = {US},
  keywords = {formula,instantiation,triplets,unit,variables},
  file = {C\:\\Users\\disc\\Zotero\\storage\\VY3VKFAV\\US5276897.pdf}
}

@inproceedings{TID20,
  title = {A {{SAT-Based Approach}} for {{Index Calculus}} on {{Binary Elliptic Curves}}},
  booktitle = {Progress in {{Cryptology}} - {{AFRICACRYPT}} 2020},
  author = {Trimoska, Monika and Ionica, Sorina and Dequen, Gilles},
  year = {2020},
  month = jul,
  pages = {214--235},
  address = {{Cairo, Egypt}},
  doi = {10.1007/978-3-030-51938-4},
  abstract = {Logical cryptanalysis, first introduced by Massacci in 2000, is a viable alternative to common algebraic cryptanalysis techniques over boolean fields. With xor operations being at the core of many cryptographic problems, recent research in this area has focused on handling xor clauses efficiently. In this paper, we investigate solving the point decomposition step of the index calculus method for prime-degree extension fields F2n , using sat solving methods. We experimented with different sat solvers and decided on using WDSat, a solver dedicated to this specific problem. We extend this solver by adding a novel symmetry breaking technique and optimizing the time complexity of the point decomposition step by a factor of m! for the (m + 1) th summation polynomial. While asymptotically solving the point decomposition problem with this method has exponential worst time complexity in the dimension l of the vector space defining the factor base, experimental running times show that the presented sat solving technique is significantly faster than current algebraic methods based on Gr\"obner basis computation. For the values l and n considered in the experiments, the WDSat solver coupled with our symmetry breaking technique is up to 300 times faster than Magma's F4 implementation, and this factor grows with l and n.},
  keywords = {Discrete logarithm,dpll algorithm,Elliptic curves,Index calculus,Point decomposition,Satisfiability,Symmetry},
  file = {C\:\\Users\\disc\\Zotero\\storage\\TNPPS2TN\\Trimoska et al. - 2020 - A SAT-Based Approach for Index Calculus on Binary .pdf}
}

@article{VB03,
  title = {Effective Use of {{Boolean}} Satisfiability Procedures in the Formal Verification of Superscalar and {{VLIW}} Microprocessors},
  author = {Velev, Miroslav N and Bryant, Randal E},
  year = {2003},
  month = feb,
  journal = {Journal of Symbolic Computation},
  volume = {35},
  number = {2},
  pages = {73--106},
  issn = {0747-7171},
  doi = {10.1016/S0747-7171(02)00091-3},
  abstract = {We compare SAT-checkers and decision diagrams on the evaluation of Boolean formulae produced in the formal verification of both correct and buggy versions of superscalar and VLIW microprocessors. The microprocessors are described in a high-level hardware description language, based on the logic of equality with uninterpreted functions and memories (EUFM). The formal verification is done with Burch and Dill's correctness criterion, using flushing to map the state of the implementation processor to the state of the specification. The EUFM correctness formula is translated to an equivalent Boolean formula by exploiting the property of positive equality, and using the automatic tool EVC. We identify the SAT-checkers Chaff and BerkMin as significantly outperforming the rest of the SAT tools when evaluating the Boolean correctness formulae. We examine ways to enhance the performance of Chaff and BerkMin by variations when generating the Boolean formulae. We reassess optimizations we developed earlier to speed up the formal verification.},
  langid = {english},
  file = {C\:\\Users\\disc\\Zotero\\storage\\5BRMAKV6\\Velev and Bryant - 2003 - Effective use of Boolean satisfiability procedures.pdf;C\:\\Users\\disc\\Zotero\\storage\\YUDJH4RD\\S0747717102000913.html}
}

@inproceedings{ZMMM01,
  title = {Efficient Conflict Driven Learning in a {{Boolean}} Satisfiability Solver},
  booktitle = {{{IEEE}}/{{ACM International Conference}} on {{Computer Aided Design}}. {{ICCAD}} 2001. {{IEEE}}/{{ACM Digest}} of {{Technical Papers}} ({{Cat}}. {{No}}.{{01CH37281}})},
  author = {Zhang, Lintao and Madigan, C.F. and Moskewicz, M.H. and Malik, S.},
  year = {2001},
  pages = {279--285},
  publisher = {{IEEE}},
  address = {{San Jose, CA, USA}},
  doi = {10.1109/ICCAD.2001.968634},
  isbn = {978-0-7803-7247-4},
  file = {C\:\\Users\\disc\\Zotero\\storage\\N2S83CW7\\Zhang et al. - 2001 - Efficient conflict driven learning in a Boolean sa.pdf}
}


